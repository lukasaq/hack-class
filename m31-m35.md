### CDAH-M31L1-Identify and Contain Malicious Activity  ###

Containment, Eradication, and Recovery Phase Overview
Below, Figure 31.1-1 displays the four phases of the continuous Incident Response (IR) lifecycle. When CPTs are not actively responding to an incident, they are in the Preparation phase of IR. In this phase, CPTs maintain readiness through deliberate mission planning, preparation, execution, and assessment. A CPT's work in IR is intended to supplement a local organization's network defenders. When CPTs arrive on site, they enter the Detection and Analysis phase by conducting their own Mission Analysis (MA). A CPT begins the Containment, Eradication, and Recovery phases of IR only after the operation has been approved, in accordance with the processes and tasks determined during the earlier phases of IR.
<img width="3330" height="1669" alt="image" src="https://github.com/user-attachments/assets/6de040da-b23a-432e-b331-21ff7ab72020" />

The containment process in IR is driven by the following two primary goals:
Prevent the incident from causing additional damage to organizational assets.
Preserve malware and forensic artifacts.
During this third phase of IR, analysts begin working actively with affected systems and hosts. Analysts start this phase with a focus on threat hunting and containment to minimize damage to organizational assets. Thereafter, the focus shifts to eradication, recovery, or mitigating strategy processes. Primary and critical containment tasks may include disabling network connectivity, enabling firewalls, creating forensic images, and powering down the host. 


Preserving malware and forensic artifacts during the Containment phase can assist analysts in future operations and phases of IR. Forensic evidence that has been properly obtained with a well-documented chain of custody can be used in legal proceedings. Preserved malware and forensic artifacts can also provide critical information to guide decision-making and strategic planning as the IR lifecycle progresses


-------------


Analyze Hosts for Malicious Activity
Read the scenario below, then complete the lab in the Virtual Machines (VMs) it-maint-0, ls-wkstn-3. Use the VMs to answer the upcoming series of questions and analyze different hosts for more information.

﻿

Scenario 
﻿

Security analysts identified a host within the organization that has been infected with malware. The malware is known to quickly spread among hosts on the network, especially hosts that have recently established connections with other hosts. The CPT is investigating two hosts that they suspect may be infected by the malware. The host ls-wkstn-3 may have been exposed to malware through communications with the host ls-wkstn-2. Additionally, ls-wkstn-3 recently communicated with host it-maint-0, which is responsible for remoting into hosts in the environment to provide Information Technology (IT) support. As a result, it-maint-0 connects with a large number of hosts and is easily susceptible to malware infections. The malware varies in name, but is known to maintain persistence by using folders that may be hidden and the registry. 

﻿

Table 31.1-1 and Table 31.1-2, below, present the specific IOCs associated with the malware for both Windows and Linux systems. Use this information to access and analyze both it-maint-0 and ls-wkstn-3. Determine whether the malware has spread to either host. Use static analysis for any malware detected on a host since any additional execution of the malware may spread and worsen the infection.


<img width="2500" height="886" alt="image" src="https://github.com/user-attachments/assets/e0ad715b-3f4d-4673-ab82-fc04c13fbc65" />


<img width="2500" height="1036" alt="image" src="https://github.com/user-attachments/assets/f96274c3-b806-49af-86cd-d71b04524051" />

Workflow


1. Log in to the VMs it-maint-0 and ls-wkstn-3 using the following credentials:
Username: trainee
Password: CyberTraining1! 



2. Using Table 31.1-1, analyze both VMs to identify whether either has been infected by the malware. 


3. Answer the next set of questions to start the initial examination.


---------------



Malicious Activity Overview
The analysis of both it-maint-0 and ls-wkstn-3 determined that ls-wkstn-3 is likely infected with the malware found in the environment. Further analysis must be completed to determine whether other artifacts are present. 

﻿

Identify Additional Artifacts from Malicious Activity
﻿

Continue using static analysis to work in ls-wkstn-3. Discover whether additional artifacts from the previously identified malicious activity exist. 

﻿

Workflow
﻿

1. Within ls-wkstn-3, review the registry for any persistence mechanisms placed by the malware. 

﻿

2. Answer the next set of questions to continue the examination.



------------------

Host Containment
IR containment is the process of keeping harmful items or actions under control to prevent further damage from occurring. These harmful artifacts include processes, applications, and software. Analysts must prioritize containment efforts and employ containment measures quickly. Fast and efficient containment saves network resources and provides critical time for analysts to develop a long-term remediation plan. For containment to be efficient, it should employ the least amount of work possible, while maximizing the prevention of damage. 

﻿

Containment strategies vary based on the specific details of an incident. For example, if a host is infected with Command and Control (C2) malware and is actively connecting to external Internet Protocol (IP) addresses, the strategy may be to take the infected host offline. Containment plans may require teams to complete the following tasks:

Remove network connectivity on the host or router.
Lock user accounts.
Stop specific services or ports.
Shut down the infected host.
If a containment plan requires shutting down a host, analysts must attempt to collect a memory dump prior to shutdown. Collecting a memory dump saves the host's volatile memory, which would otherwise be lost in a shut down.



-----------------


Containment Strategy
In the lab scenario, there are many unknowns surrounding the malware infection on host ls-wkstn-3. The following are just some of the basic details the analysts have yet to learn about the malware:

The method by which it was placed on the host
Its ease of spreading to other hosts in the environment
Its scope of impact 
Its behavior on impact and thereafter
Its goal
Its target
Due to the unknown components, the containment strategy must prioritize preventing any further spread of the malware and aim to preserve any artifacts associated with it. The strategy is to remove all network connections between ls-wkstn-3 and the environment and keep the host powered on to allow the CPT to continue any preservation tasks such as hashing files, collecting a memory dump, or saving artifacts. 

﻿

Implement Containment
﻿

Continue working on infected host ls-wkstn-3. Access the hosts Command Line Interface (CLI) to view and remove network connectivity, as described in the above containment strategy. Upon removal, verify the network connections are disabled. 

﻿

Workflow
﻿

1. Log in to the VM ls-wkstn-3 using the following credentials:

Username: trainee
Password: CyberTraining1! 
﻿

2. Right-click the Windows Start icon on the toolbar and select Command Prompt (Admin).

﻿

3. Select Yes in the dialog box with the prompt Do you want to allow this app to make changes to your device? 


----------------

Implement Containment
﻿

The command netsh interface show interface returns all network interfaces for the host. Its current output displays that the host contains the interfaces Ethernet1 and Ethernet0. Both interfaces are connected and enabled.

﻿

Remove Network Connectivity for Containment
﻿

Continue working on infected host ls-wkstn-3. Remove network connectivity, as described in the containment strategy.

﻿

Workflow
﻿

1. In the Command Prompt (Admin), disable the interface ﻿Ethernet0.


-----------

Remove Network Connectivity
The command netsh interface set interface Ethernet0 disable disables the interface Ethernet0.

﻿

Verify Changes for Containment
﻿

Continue working on infected host ls-wkstn-3. Verify that network connectivity has been completely disabled.

﻿

Workflow
﻿

1. Verify the network interfaces have been disabled by executing the following command:

netsh interface show interface 


-----------

### CDAH-M31L2-Preserve Evidence During IR ###

Evidence Authenticity and Integrity
Chain of Custody
﻿

The most critical process of evidence documentation is the Chain of Custody document (or Chain of Custody form). The Chain of Custody document contains chronological logging and documentation of all electronic evidence on a device or host. The document is used to assure organizational leadership, law enforcement, and the court system that evidence is authentic (that is, that the same evidence collected is presented). The Chain of Custody document seeks to identify the who, what, where, when, and how of evidence collection, storage, and control access. 	

﻿

A robust Chain of Custody document should include such information as the following:

Information identifying the analyst responsible for the evidence collection.
An overview and description of the evidence, which may include the following:
What evidence was collected. 
Where the collection occurred; this may be a virtual path or a physical location.
When (the date and time in local and Greenwich Mean Time [GMT]) the evidence was collected.
Who has custody of the evidence and when they took custody.
Where any physical evidence is located; for example, “A Compact Disk (CD) containing forensic artifacts is secured in safe number 101A, in room 404 (evidence storage room), of the headquarters building.” 
﻿Figure 31.2-1 provides an excerpt of a Chain of Custody document example from the National Institute of Standards and Technology (NIST)

<img width="867" height="576" alt="image" src="https://github.com/user-attachments/assets/07821d26-745c-4c71-b824-3472c262c1d5" />


-------------


Protecting Digital Evidence Integrity
Similar to creating a Chain of Custody document, organizations may create standardized policies and procedures for documenting the evidence collection. The policies and procedures are specific to the organizational needs and may vary, based on department. Such documentation aims to process and protect the integrity of the evidence and the organization. 

﻿

Organizational policies may include the following information: 


Department and analyst information, identifying the department and analyst conducting collection operations. This may include name, organizational contact information, and phone number. 
When the evidence was collected, with date and time in both local time and GMT.
Where the evidence was collected; this may be a virtual path or a physical location.
The platform, tools, and steps used to collect the evidence. 
A list of identifying features, such as the evidence, hashes, metadata, and timestamps (including such data as date created and date edited), and screenshots of relevant information (timestamps, hashes, metadata, etc.).
Description of how the evidence is stored (for example, a secure Portable Document Format [PDF] file, a password-protected Microsoft Word document, or an encrypted archive file used to save the relevant data). The hashes/checksums and identifying information of the secure documents can also be added to the Chain of Custody document as an additional method of ensuring evidence integrity to ensure authorities’ authenticity.


-------------

Forensic Tools for Digital Evidence Integrity Validation
Forensic tools are used by analysts to authenticate and prove the integrity of the evidence collected during the investigation. Through the use of imaging, forensic tools allow analysts to create a copy of the environment at a specific point in time. The created image is placed into a sandbox environment that provides validation for, and allows analysts to research further, the information contained in the Chain of Custody document. Examples of tools that analysts leverage to aid in an investigation are FTK® Imager, OpenText™ EnCase™ Forensic, Volatility, and ExifTool

---------


Evaluate Data Integrity
Read the scenario below, and complete the steps in the workflow to verify data collected in a Chain of Custody document.

﻿

Scenario 
﻿

A host has been infected with malware, and a Cyber Protection Team (CPT) has been tasked with, and has completed, Incident Response (IR) operations. The host was removed from the network, imaged, and shut down to mitigate damage. The Chain of Custody document (attached) was completed. The CPT requires analysis to verify the data collected in the Chain of Custody document. Access the host’s image, and verify the data contained in the Chain of Custody document.

﻿

Workflow
﻿

1. Open the Virtual Machine (VM) ls-wkstn-3. The login credentials are as follows:

Username: trainee
Password: CyberTraining1! 
﻿

2. Using the Windows PowerShell cmdlet Get-FileHash, generate MD5 hashes for evidence files. Use the following format, replacing {FILENAME} with each file listed in Table 31.2-1:

Get-FileHash {FILENAME} -Algorithm MD5


<img width="2500" height="889" alt="image" src="https://github.com/user-attachments/assets/142ba4f7-6619-4fa3-941e-04b405e93384" />

3. Verify the timestamps included in the Chain of Custody document.


Use this workflow to answer the following questions.


Keep the VM ls-wkstn-3 open, as it is used in an upcoming workflow

-------------

Unvalidated Data
The hash of the hosts file and timestamp values in the documentation do not match the information found on the host. The file’s data could not be verified, and further investigation regarding the difference is needed.


----------

Data Acquisition Overview
In a digital forensic investigation, data acquisition is the process of discovering, gathering, and recovering sensitive data. Therefore, cyber analysts need to understand the process of accessing, retrieving, restoring, and protecting the data. Data acquisition is achieved through forensic imaging using such software as FTK Imager, SIFT™ Workstation from SANS™ Institute, and EnCase Forensic.

﻿

Acquiring data for forensic evidence is possible via four methods:

Disk-to-disk: Uses hardware to create an exact copy of a source hard drive.
Disk-to-image: Makes a copy of a hard disk and saves the data as a file, such as an Optical Disk Image, or ISO, file. 
Logical: Creates a bit-for-bit copy of forensic data from only specific files or artifacts of interest. 
Sparse: Targets specific files and collects fragments of unallocated or deleted data.


--------------

Forensic File Formats
Data acquisition through forensic tools may use one of three primary file formats: RAW, proprietary, or Advanced Forensic.

﻿

RAW Format
﻿

The RAW file format is used by the Linux command dd (copy and convert command) to create exact copies of data. Analysts use this utility to create an exact bit-for-bit copy of a RAW disk or volume as a file. The RAW format allows for fast data transfers and supports a wide range of forensic tools. The RAW format requires disk space identical in size to the source data for the copy. 

﻿

Proprietary Formats 
﻿

Software vendors may create proprietary forensic file formats based on their own tools or applications. Proprietary format examples are AD1 files used by FTK Imager and E01 files used by EnCase Forensic.  Proprietary formats may contain functionality to compress or add segmentation or metadata to the image file, all of which increase efficiency and use of the image. A proprietary format is commonly exclusive to the tool or application it was created to support. 

﻿

Advanced Forensic Format
﻿

Designed as an alternative to proprietary formats, Advanced Forensic Format (AFF) is an open-source, flexible format easily shared between organizations with different forensic tools. AFF allows extensive metadata information to be stored with the image, consumes less disk space than EnCase Forensic or FTK Imager image formats (through compression and segmentation), and contains robust gathering and storing functionality.

﻿

Table 31.2-2 provides a list of common forensic applications and their supported image file formats:


<img width="2500" height="1184" alt="image" src="https://github.com/user-attachments/assets/285bb676-bc13-4115-be09-672c8a1750f3" />



------------


Acquire a Forensic Image
Read the scenario below, and complete the steps in the following workflow to acquire a logical forensic image in E01 format for analysis.

﻿

Scenario 
﻿

More information has been uncovered regarding the infected host incident described in the prior exercise. The CPT requires help acquiring a logical forensic image for host ls-wkstn-3 before the host is shut down. The team has requested that the image be collected in E01 format. 

﻿

The VM ls-wkstn-3 should still be open from the prior workflow. If it is not open, log in to ls-wkstn-3 using the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

Workflow 
﻿

1. Open FTK Imager. Select Yes when prompted Do you want to allow this app to make changes to your device?﻿

﻿

2. In FTK Imager, select File > Create Disk Image…﻿

﻿

3. In the Select Source window, select Logical Drive, and select Next. 

﻿

4. In the Select Drive window, select C:\ - [NTFS], and select Finish.

﻿

5. In the Create Image window, under Image Destination(s), select Add…﻿

﻿

6. In the Select Image Type window, select E01, and select Next.

﻿

7. In the Evidence Item Information window, enter the following information:


Case Number: FN2187
Evidence Number: 1
Unique Description: Image of ls-wkstn-3
Examiner: trainee
Notes: <leave empty> 

8. In the Select Image Destination window, enter the following information, as shown in Figure 31.2-1:


Image Destination Folder: E:\
Image Filename: ls-wkstn-3_image
Image Fragment Size: 1500
Compression: 6
Use AD Encryption: <leave unchecked>

<img width="864" height="644" alt="image" src="https://github.com/user-attachments/assets/5cc1978b-8a69-47ca-963b-036dad887f0f" />

NOTE: E:\ is a separate drive used for evidence collection. 


9. Select Finish.


10. Select Start to begin the creation of the image. Imaging of the logical disk may require up to 20 minutes to complete.


Use this exercise to answer the following question


-------------

### CDAH-M32L1-Strategize Threat Mitigation ###

Develop a Threat Mitigation Strategy
Host threat mitigation consists of two key responsibilities. The first responsibility is to eliminate the threat. The second responsibility is to improve defensive capabilities for preventing both continuing and future exploitation by similar threats. Although various strategies are available for threat mitigation, defense teams must strive to choose strategies that allow successful fulfillment of both threat mitigation responsibilities.

﻿

The following steps help defense analysts identify the best strategies to mitigate threats:

Analyze malicious activity.
Plan threat mitigation.
Develop a threat mitigation strategy.
Step 1: Analyze Malicious Activity
﻿

The IR team must complete an initial set of IR tasks before beginning mitigation. During the first phase of IR, Preparation, mission planning is conducted to identify critical systems, available security tools, and tactics. The second phase, Detection and Analysis, involves identifying and investigating malicious activity. The third phase of IR has three key goals: Containment, Eradication, and Recovery. After Containment, this phase requires analyzing malicious activity to strategize post-incident actions that fully mitigate the threat. Strategizing threat mitigation ensures that all known aspects of the malicious activity are accounted for when completing Containment, Eradication, and Recovery.

﻿

Malicious Email Attachment Scenario
﻿

Figure 32.1-1, below, illustrates a scenario in which the following malicious activity was identified during Detection and Analysis:

Host A was compromised after downloading an email containing a malicious HTML file attachment. Opening the malicious attachment executed JavaScript code that automatically downloaded a second-stage malware payload from an external IP address.
Hosts B and C were compromised because they share a vulnerability that was exploited by the malware delivered from Host A.
Hosts D and E on the network also received the malware from Host A but were not compromised because they were not vulnerable to the attack.

<img width="2500" height="1805" alt="image" src="https://github.com/user-attachments/assets/30326259-e3cf-4d74-9bb4-989c2a04b19f" />


An analysis of the scenario and identification of all hosts involved provides critical direction for the Containment, Eradication, and Recovery phase of IR. All hosts that received the malware require remediation, as summarized below:
Hosts A, B, and C were compromised by multiple forms of malware, so these hosts must be cleansed of malware and returned to a known good software configuration.
Hosts D and E received the malware and, although they were unaffected, must be cleansed of the malware from Host A.


After identifying the necessary mitigation actions, the next step is to plan how to implement the actions by creating a mitigation strategy.


Step 2: Plan Threat Mitigation


Although the second phase of IR involves significant analysis, the third phase of IR extends this analysis as part of its containment, eradication, and recovery planning efforts. The goal of the second phase of IR is to detect and analyze malicious activity and contain a potential breach. By contrast, one of the goals of the third phase is to correlate malicious activity with known threat behavior. The distinction between the two phases is most apparent when planning actions to mitigate the risks involved with threat behavior. This type of planning is critical for the third phase, but may be overlooked during the second phase of IR.


In the malicious email attachment scenario, Host A was compromised by malware, leading to additional malware compromising Hosts B and C. Actions during the second phase of IR likely did not include patching the vulnerable software on Hosts B and C, which were exploited by the malware. Additionally, the malicious email that was the root of the compromise may have been delivered to others in the organization. These emails need to be removed from all email accounts and measures need to be taken to prevent similar emails from being delivered. This attention to the risks involved in the compromise in the third phase of IR allows for containment, eradication, and recovery.


Development of a threat mitigation plan involves taking into consideration the analysis performed during the second phase of IR and applying this information to understand how the threat was successful. Applying the information includes remediating vulnerable software, malicious system changes to hosts, and user behavior that allowed the compromise. The IR team should also consider current policies and procedures that may be flawed. Deliberating and examining these considerations is similar to the actions performed by the threat actor. By understanding the weaknesses in the operating environment, better defenses and longer-lasting mitigations can be developed to help prevent future exploitation. According to the analyses, these defenses may include educating users about threats and safe work practices, revising policies and procedures, and implementing system and network changes.


In summary, threat mitigation planning involves both addressing the security concerns identified in the second phase of IR, as well as evaluating the operating environment to understand how the threats were successful in the first place. This allows the IR team to remediate both the immediate security concerns as well as to perform preventative maintenance to address the roots of the problem in the third phase of IR.


Step 3: Develop a Threat Mitigation Strategy


During the incident response process, three host machines were identified as compromised by malware. Review the information gathered through IR analysis and develop a strategy to mitigate the threats.


Workflow


1. Log in to the Virtual Machine (VM) win-hunt using the following credentials:
Username: trainee
Password: CyberTraining1!



The IR team marked two files on this system as malicious.


2. Confirm the marked files are present on the system by opening a Command Prompt and navigating to their respective folders at the following directories:
C:\Users\trainee\Downloads\mailbox_cleaner.html
C:\Windows\Temp\sjuKKE82234.bin
The IR team’s report on the present incident states that malicious code exists in the file malibox_cleaner.html. This file was downloaded from an email attachment sent to a particular user, who then opened the file. The malicious file sjuKKE82234.bin was then downloaded to C:\Windows\Temp. Immediately afterwards, the hosts lin-hunt-cent and sift, on the same subnet as win-hunt, were compromised by malware. File transfer activity occurred between win-hunt and multiple other hosts, including lin-hunt-cent and sift but no additional malware compromises were discovered.


3. Log in to the VM lin-hunt-cent using the following credentials:
Username: trainee
Password: CyberTraining1!



The IR team marked one file on this system as malicious. 


4. Confirm the marked is present on the system by opening Terminal and navigating to its folder:
/opt/j8UHjdye45
The IR team investigated this executable file and determined that it exploits a common Linux application. The vulnerability was recently discovered and the software vendor provided the patch. Until remediated, this vulnerability allows for arbitrary remote command execution at an administrative level. No further malicious activity was detected on this host.


5. Log in to the VM sift using the following credentials:
Username: t
rainee
Password: CyberTraining1!



The IR team marked one file on this system as malicious.


6. Confirm the marked file is present by opening Terminal and navigating to its folder:
/opt/adWE9034
The IR team investigated this file and found it to be nearly identical to the malicious file found in the same folder on the host lin-hunt-cent. However, additional malicious activity was detected on this system. The following seven folders containing forensic evidence were accessed and encrypted within the cases folder within the root directory:
/cases
case1
case2
case3
case4
case5
case6
case7

The team discovered that these folders allowed full permissions to read, write, and execute for any user on the system. As a result, it is unknown if the malicious actor simply removed availability to these case files through encryption or if the sensitive information was accessed as well.


The three systems, win-hunt, lin-hunt-cent, and sift, were all infected with malware that originated from a user accessing a malicious email attachment on win-hunt. Malware was then distributed from win-hunt to lin-hunt-cent and sift which exploited a vulnerability in a commonly used Linux application. While no further malicious activity was detected on lin-hunt-cent, encryption of forensic case files and potential exfiltration of sensitive information occurred on sift, due in part to excessive folder and file permissions.


Use the information from this lab to strategize mitigation in the following questions


-----------


Incident Response Roles for Threat Mitigation
Although the Containment, Eradication, and Recovery phase of IR involves similar roles as in previous phases, individuals outside of the typical IR team may need to step in to fulfill specific duties at this stage. Understanding the operating environment and roles within the organization are necessary to choose the appropriate roles to mitigate threats.

﻿

Threat Mitigation
﻿

The IR tools used in previous phases, such as a SIEM and host monitoring tools found in the Sysinternals Suite, are also useful for verifying remediation in the Containment, Eradication, and Recovery phase. For example, the removal of malware and malicious system settings for malware persistence is expected to result in a change in system log activity, such as the removal of processes performing malicious network connections. This change in activity should be verified through host monitoring tools and SIEM queries and dashboards.

﻿

IR Roles in Threat Mitigation
﻿

Typical IR teams include the roles described in Table

<img width="2500" height="1113" alt="image" src="https://github.com/user-attachments/assets/b9789642-bb18-4bfc-ba93-37e90f2bf8ba" />

In addition to these roles, others may lend their talents in the IR process to perform forensics, system administration, user administration, vulnerability management, and other functions necessary to mitigate a threat. Depending on the operating environment and availability of staff, the IR Manager may require the IR team and additional personnel to perform mitigation activities.


An IR Manager plans threat mitigation roles as part of IR. This includes determining what roles are required for mitigation for both general purpose incidents as well issues that occur less often. General incidents include those regarding common security issues such as malware compromise and successful phishing attacks. Uncommon issues include large-scale security breaches. The results from the Detection and Analysis IR phase heavily determines the activities that are required for remediation. The IR Manager uses this information when assigning responsibilities to existing roles and coordinating efforts with other teams to draw upon their technical expertise concerning compromised systems.


Malicious Email Attachment Scenario


In the malware compromise scenario, it was determined that Hosts B and C were vulnerable to malware due to a common software vulnerability. The IR Team may be technically proficient in discovering and removing malware, but they may not have the authority or expertise to patch the vulnerable software to prevent future exploitation. In this case, the system administrator responsible for these hosts may be contacted to perform the necessary software patching and testing to ensure that the vulnerability is no longer present and that the application of the patch did not hinder any necessary functions of the hosts.


In summary, a successful mitigation of a threat not only removes the ability for an attacker to repeat an exploit, but also ensures that the mitigation strategy does not interfere with the normal, day-to-day operation of the host systems. This is one reason why it is important to develop a holistic threat mitigation strategy.

-------------


### CDAH-M32L2-Neutralize Threats ###

CPT Threat Mitigation Functions
An incident has occurred. The CPT is working to determine and carry out a threat mitigation strategy. Threat mitigation begins by understanding the system changes a malicious program has made on an infected host. 

﻿

System changes are defined and categorized as Indicators of Compromise (IOCs) associated with the malware. IOCs are determined by performing static and dynamic analysis of the malware. Once host analysts analyze the malware and determine IOCs, removal and neutralization of the threat begins.

﻿

A CPT performs the following steps when mitigating threats: 

Identify malware-related IOCs
Remove malicious artifacts
Determine and perform threat mitigation
Identify Malware-related IOCs
﻿

There are various types of malware. Each malware type includes its own design, file size, and functionality.  The wide range of malware types makes it impossible to use one solution for eliminating all malware threats. 

﻿

Dynamic Analysis
Dynamic analysis allows Host Analysts to identify actions that are performed by malware in order to compromise a system. Dynamic analysis is best performed in a sandbox environment, such as Cuckoo.

﻿

Malware-related IOCs may include basic events such as the creation of files with names that follow a prescribed pattern of characters, or the modification of a specific Windows Registry key. When these specific actions are observed and analyzed, they are recorded as IOCs associated with the malware. Once behaviors are identified on a compromised host, all malicious presence is removed and the threat is neutralized.

﻿

Removal of Malicious Artifacts
﻿

A threat mitigation strategy defines different options that exist for eliminating adversarial presence on a compromised host. The strategy can include actions ranging from re-imaging a system to removing malicious artifacts.

﻿

Re-imaging a system is most efficient for user workstations, however systems in an Industrial Control System (ICS) environment often require the removal of malicious artifacts. For this reason, identifying malware-related IOCs is necessary to ensure that the threat is entirely removed. If a malicious binary remains on the host, it is possible for the malware to execute in the future and perpetuate further compromise. 

﻿

Perform Threat Mitigation
﻿

After malware activity and artifacts have been observed and identified, the next step is to determine how to perform threat mitigation activities on the compromised hosts. 

﻿

An infection of malware is rarely limited to a single host. The manual removal of malicious artifacts on each host can be tedious, time-consuming, and inefficient. In the event of a malicious compromise across several hosts, automated solutions for threat mitigation must be explored. Using tools, such as PowerShell, allows analysts to create and run scripts to perform the necessary checks and removal of malicious artifacts.


-----------

Threat Neutralization
Threat neutralization is a crucial function of a CPT to minimize exposure to risks such as the theft of user credentials, the execution of malicious code, or the loss of systems, resources, and sensitive information. 

﻿

The steps for performing threat neutralization are as follows:

Identify malware activity.
Identify behavior indicating a compromise.
IR scripting and remote access.
Identifying Malware Activity
﻿

Malware activity can be identified using dynamic and static analysis of malicious code. Once an executable file has been identified as malicious, observing system changes often leads to the discovery of artifacts that can be used in the investigation.

﻿

Malware analysis allows the CPT to observe and experience malicious behavior in order to determine the likelihood of a compromise. When hunting for signs of host compromise across a network, the use of IR scripts can be more efficient than manually inspecting each system. 

﻿

The first step in neutralizing a threat is to identify the actions performed by the malicious code. These actions are observed with the help of a sandbox tool, such as Cuckoo, which is used in upcoming workflows.

﻿

Scenario
﻿

Using the ZeuS trojan as an example, ZeuS is capable of monitoring internet activity and recording user keystrokes. Suppose ZeuS was delivered to a victim through the use of phishing emails and malicious drive-by downloads. 

﻿

The Suspicious Process
Through the monitoring of host network activity, the download of an executable file can be detected, copied, and uploaded to Cuckoo for analysis. 

﻿

Cuckoo's analysis report provides information about the changes made by the malware, and the creation of the following suspicious process:

C:\Windows\system32\cmd.exe"/c "C:\Users\Bob\AppData\Local\Temp\tmp2aw5421d.bat
﻿

This suspicious process consists of a call to the built-in Windows command interpreter, cmd.exe, followed by the /c parameter. This instructs cmd.exe to execute a certain batch file found within a temporary directory. A batch file is a script containing executable instructions. This file is suspicious because it includes the execution of a binary file from inside another binary file. 

﻿

The Executed Batch File
The executed batch file resides in a temporary directory, suggesting that it was created by the executed malware. Cuckoo identified the creation of the batch file 2b828b74d57876f4_tmp2ae5421d.bat from the observed behavior, and determined that it was used to delete the original binary.

﻿

The behavior is an attempt by the malware to hide itself within the infected system. Eliminating the original malware executable covers evidence of the malware, and likely resulted in the creation of a new file containing malicious code. Understanding this type of activity allows an analyst to recognize behavior that indicates another host has been infected.

﻿

The Registry Change
The following code block displays activity observed by Cuckoo, showing the modification of the Windows Registry:

HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Run
C:\Users\Bob\AppData\Roaming\Vaxw\tuiha.exe
﻿

Cuckoo describes the registry change as a method to automatically run the malware at boot. The specific key is described and controls specific programs that will automatically execute when a user logs on to Windows. 

﻿

The New File
Additionally, the registry change includes the file path to a hidden folder in a user’s directory. Notably, this is not a temporary directory. Furthermore, the executable designated in this key, tuiha.exe, is not the name of the original malicious file submitted for Cuckoo analysis, nor the name of the subsequent batch file that deleted it. 

﻿

Instead, tuiha.exe is a new file in a new subdirectory of the user’s AppData\Roaming folder. Assuming that the malware created this subdirectory and executable file, the existence of a similar directory in another system may indicate a compromise.

-----------

Identifying IOCs
The second step in neutralizing a threat is to identify behavior that indicates a compromise. 

﻿

This step is completed by discovering system changes made to a host by the malware. Although similar to the first step, this step results in CPTs arriving at a clearly defined set of IOCs associated with the malware.

﻿

Scenario Continued
﻿

Windows Sysinternals suite can be used to identify malicious behavior. Given that many of these artifacts involve system processes, Process Monitor can be used to discover and confirm file system and registry changes. 

﻿

The Executed Batch File
The ZeuS trojan, analyzed in Cuckoo, was executed on a Windows system. Shortly after, Process Monitor collected data pertaining to the creation of a process. 

﻿

The process includes the execution of the following batch file:

sample4.exe Process Create PID 2872 Command line: 
"C:\Windows\system32\cmd.exe"/c "C:\Users\Bob\AppData\Local\Temp\tmpb577ffe6.bat"
﻿

When an executable file is opened in Windows, a new process is created with the same name as the executable file. The ZeuS trojan is named sample4.exe. Process Monitor recognized the creation of the new process by sample4.exe and assigned to it the Process Identification Number (PID) 2872. 

﻿

The new process consisted of a call to the Windows built-in command interpreter with a command to execute a certain patch file in a temporary directory. This behavior is identical to the created suspicious process that was observed by Cuckoo in the sandbox. 

﻿

Identifying a Pattern
The name of the batch file is different from the one observed in Cuckoo due to randomization used by the malware. However, a pattern can be observed. Both file names begin with tmp, followed by eight alphanumeric characters, and end with .bat. The way these files were named may be according to a pattern, and knowledge of this can aid in automated detection of malicious activity.

﻿

Process Monitor also observed the modification of a Windows Registry value used to run an executable whenever a user logs on. The output from Process Monitor is as follows:

lodya.exe 3044 RegSetValue HKCU\Software\Microsoft\Windows\CurrentVersion\Run\{731…SUCCESS}
C:\Users\Bob\AppData\Roaming\Sywau\lodya.exe
﻿

This record describes that a process named lodya.exe successfully issued an instruction to set a registry key value. This key controls which programs automatically execute when a user logs on to Windows, and it is included in the Cuckoo report. 

﻿

Discovered IOCs
The malware behavior reported by Cuckoo was associated with activity found on a compromised host, using Sysinternals. The discovered IOCs as a result of this step include the creation of malicious batch files, executable files, and registry key values


-----------

IR Scripting and Remote Access
After IOCs are identified, they can be removed using scripting and remote access.

﻿

In PowerShell, the Get-Item cmdlet returns a specified item from a specified location and can be used to discover registry key values. 

﻿

Figure 32.2-1 below shows the cmdlet used to obtain the persistence mechanism planted by the ZeuS trojan

<img width="1210" height="132" alt="image" src="https://github.com/user-attachments/assets/6eb82722-7868-4ae7-b61d-e013468e659d" />

Once malware is found, PowerShell can be used to scan multiple hosts for malware persistence more quickly than accessing and manually analyzing Process Monitor on each individual host.


The Get-ChildItem cmdlet returns items found within a specified container. 


As shown in Figure 32.2-2 below, Get-ChildItem can be used to return the top five recently-modified files in a directory

<img width="904" height="620" alt="image" src="https://github.com/user-attachments/assets/8e26d050-2e2b-4796-8102-52bf953ec303" />

This information can be used to help search for the folders used by ZeuS to store its persistent executable file.


The cmdlets are available through an interactive terminal, however their true value comes from the ability to call them in a PowerShell script. A script allows for quick execution and can be deployed to systems across a network to search for a compromised host. The following script uses the discovered IOCs to help to find the compromise:
$path1 = 'C:\Users\Bob\AppData\Local\Temp'
$path2 = 'C:\Users\Bob\AppData\Roaming'
$pattern1 = 'tmp\w{8}.bat'
$pattern2 = '\w{5}.exe'

Get-ChildItem $path1 -recurse | where {$_.name -match $pattern1} | Select name
Get-ChildItem $path2 -recurse | where {$_.name -match $pattern2} | Select name

---------

Dynamic Analysis
Dynamic analysis is the process of executing malware in a sandbox environment and observing its behavior. A malicious Python script was found operating in the network. Analysis of the script has not yet been completed. 

﻿

Access an Ubuntu workstation and use Cuckoo to perform dynamic analysis of the malware. 

﻿

Workflow
﻿

1. Open the Virtual Machine (VM) cuckoo with the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

When an alert appears, as shown in Figure 32-2.3 below, select OK

<img width="588" height="237" alt="image" src="https://github.com/user-attachments/assets/55a98436-c886-48f4-991a-76fcdd16e43d" />

2. Open a new Terminal window. Enter the following command to start the Cuckoo Web User Interface (UI):
cuckoo web -H 0.0.0.0 -p 8080

 ﻿
6. Open Firefox ESR. Enter and navigate to the following Uniform Resource Locator (URL):
http://localhost:8080



7. Select Submit A File For Analysis from the Cuckoo dashboard.


8. Select the forge.py file from the Desktop. 


9. Select Submit.


10. Select Analyze on the Configure Your Analysis page. 


11. Allow Cuckoo to run the analysis. When the Task is indicated as Reported, select the Task.


Review the report and answer the following question

----------

Malicious Registry Key
Figure 32.2-4 below shows the malicious registry key, located on the Summary tab of the report, in the Signatures section

<img width="2048" height="695" alt="image" src="https://github.com/user-attachments/assets/198893a0-d83b-4016-9d1a-f2772c535e9a" />

The following registry key ensures the malicious binary is executed at host boot:
C:\Windows\System32\driverupd.exe
Computer\HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run\DriverUpdate


--------------

Scripting to Neutralize Threats
The IR team identifies that the  forge.py  malicious script has been downloaded and placed in the C:\Users\Public\Documents path.

﻿

Use Windows PowerShell to determine if the forge.py script is present on hosts in the network, and to remove the forge.py script from compromised hosts.

﻿

Workflow
﻿

1. Log on to win-dev VM with the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

2. Open PowerShell ISE as an Administrator. 

﻿

3. Select New Script and enter the following text:

```
$hosts = Get-Content -Path C:\Hosts\Hosts.txt

$Result = ForEach ($hosts in $hosts)

    { Invoke-Command -ComputerName $hosts {Get-ChildItem "C:\Users\Public\Documents\forge.py"}}

$Final = $Result | select PSComputerName | ft -auto -wrap
$Final
﻿
```

The script defines the $hosts variable by reading the content within the Hosts.txt. The script then defines the $Result variable with a foreach loop. 

﻿

The foreach loop takes each host in the Hosts.txt file and uses the Get-ChildItem cmdlet to pull the items and child items from the C:\Users\Public\Documents\ forge.py  path.

﻿

The result of Get-ChildItem is placed in the $Final variable, where the computer name of the computer containing the forge.py file, is presented. 

﻿

4. Run the script. Review the output.


----------------

Compromised Hosts
The new script returns the following output:

Cannot find path 'C:\forge.py' because it does not exist.
    + CategoryInfo          : ObjectNotFound: (C:\forge.py:String) [Get-ChildItem], ItemNotFoundException
    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetChildItemCommand
    + PSComputerName        : cdah-wrks1

PSComputerName
--------------
cdah-wrks0
cdah-wrks2
﻿

The output confirms the file forge.py is located on hosts cdah-wr ks0 and  cdah-wrks2 on the following path: 

C:\Users\Public\Documents\forge.py



----------

Removing Files with PowerShell
Develop and run a Windows PowerShell script to quickly remove the forge.py files found on the cdah-wrks0 and cdah-wrks2 hosts. 

﻿

Workflow
﻿

1. Log on to win-dev VM with the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

2. Open the Hosts.txt file located on the following path:

C:\Hosts\Hosts.txt
﻿

3. Modify the Hosts.txt file to only include the compromised hosts cdah-wrks0 and cdah-wrks2.

﻿

4. Save and close the Hosts.txt file.

﻿

5. Open PowerShell ISE as an Administrator.

﻿

6. Select New Script. 

﻿

7. Enter the following script:

```

$hosts= Get-Content -Path "C:\Hosts\Hosts.txt" 

foreach ($onehost in $hosts) 
  {
        Remove-Item -Path "\\$onehost\c$\Users\Public\Documents\forge.py" -Force -Recurse
           }
﻿

```

The script defines the $hosts variable by reading the content in Hosts.txt. The foreach loop uses each host in the Hosts.txt file and searches for the forge.py file. If the script finds the forge.py file, it removes it from the host. 

﻿

8. Run the script.

﻿

The script executes successfull y by ret urning no errors.



----------------

Modifying the Registry Remotely
Hosts cdah-wrks0 and cdah-wrks2 are compromised with the forge.py malware. 

﻿

Use Command Prompt to remove the installed registry entry and quickly neutralize the threat.

﻿

Workflow
﻿

1. Log on to cdah-wrks0 VM with the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

2. Open Registry Editor and access the following key:

Computer\HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run\DriverUpdate
﻿

The key installed by the malware is DriverUpdate and it includes the C:\Windows\System32\driverupd.exe path.

﻿

To neutralize the malware, the key must be removed on all hosts. It is possible to manually remove the key by accessing each compromised host, however that method exhausts valuable time and resources. Instead, use the Command Prompt to save time.  

﻿

3. Log on to win-dev VM with the following credentials:

Username: trainee
Password: CyberTraining1!
﻿

4. Open Command Prompt as Administrator.

﻿

5. Enter the following cmdlet:
   

REG DELETE \\cdah-wrks0\HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run\DriverUpdate

﻿

6. When prompted to permanently delete all values under the registry key, enter Yes. 

﻿

7. Open the cdah-wrks0 VM. 

﻿

8. Open Registry Editor, and then access the key found in the following path:

Computer\HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run
﻿

The remote command accurately removes the malicious key and neutralizes the threat.

﻿

9. Complete Step 5 in this workflow once for cdah-wrks2. Use the following command:



REG DELETE \\cdah-wrks2\HKEY_LOCAL_MACHINE\SOFTWARE\WOW64
32Node\Microsoft\Windows\CurrentVersion\Run\DriverUpdate




------------

### CDAH-M33L1-Host Firewall ###

Host Firewalls
A host firewall is a piece of firewall software that runs on an individual host or device that is connected to the network. These types of firewalls provide a granular way to protect individual hosts from viruses and malware. Host firewalls allow defense analysts to control the spread of any harmful infections through the network. Most modernized organizations include host firewalls on all devices alongside an enterprise-based network firewall. 

﻿

Host firewalls monitor the traffic going in and out on a single host. They can monitor all traffic that passes through a computer's Network Interface Card (NIC) and prevent intrusions into the computer through the NIC. Many host firewalls perform multiple levels of traffic and packet analysis at various layers of the Open Systems Interconnection (OSI) model. Basic filtering is done at the network and transport layers, where the firewall may check the Media Access Control (MAC), IP address, packet source, and destination ports to determine which packets are allowed to pass.

﻿

Host firewalls can also dive deeper into the web traffic on a system and filter traffic based on the networking protocol being used. This allows users to filter the content that arrives at the machine rather than filtering where it comes from. Filtering traffic by protocol instead of only by IP address adds another layer of security to the overall system. 

﻿

Built-In Host Firewalls
﻿

Different OSs provide different host firewalls as built-in features. On Windows machines, these include Windows Firewall and Windows Defender. Linux systems provide firewalls such as iptables.

﻿

Windows Firewall
﻿

The Windows Firewall is available by default in all Windows OSs, from Windows XP and newer. The Windows host firewall provides protection to the host no matter the network it is connected to. Defenders can create Windows Firewall access control rules specifically for the machine or use the default rules that Windows creates.

﻿

Windows Defender
﻿

More modern versions of Windows, such as Windows 10, 11, and any Windows Server from 2016 and newer have Windows Defender Firewall installed by default. Windows Defender provides network traffic filtering and blocks any unauthorized traffic from entering or leaving the host device. 

﻿

Windows Defender allows users to customize all rules as well as the prebuilt default profiles that Windows uses on the OS. Windows Defender provides the following three default profiles, depending on the type of network the users connect to:

Domain: For networks that are part of a domain with accounts that get authenticated using a domain controller.
Private: For private networks, such as a home network.
Public: For high security in public networks, such as public Wi-Fi spots. 
Administrators of large enterprise networks often use the domain profile on Windows systems and configure other inbound or outbound rules. This profile provides additional security on the network, while allowing the firewall to work with other applications or software that the company is using.

﻿

Linux Iptables
﻿

Unlike Windows, most Linux-based host firewalls do not allow users to block traffic based on how applications behave. Linux-based firewalls, such as iptables, block traffic based on inbound and outbound rules that users create. Users can also create rules based on the ports that the traffic uses. For example, users may choose to allow only secure traffic and only through port 443, when using a browser. 

﻿

Host Firewall Rules
﻿

The access control rules defenders create are a significant factor in whether host firewalls can successfully stop malicious actors. Firewall rules specify the traffic and ports or processes to block or allow. Table 33.1-1, below, lists common guidelines for configuring a host-based firewall include the following


<img width="1668" height="1163" alt="image" src="https://github.com/user-attachments/assets/04139a05-37b8-4099-9c0f-7009d770c6fd" />

Users should be as specific as possible in the rules they create. Additionally, defenders may need to use subnets or port ranges when creating rules, instead of specific IPs or ports, to avoid having multiple rules that do the same thing. These additional tools also reduce rule complexity

-----------

Create Host Firewall Rules
Create firewall rules in the VM ubuntu20, with the utility iptables. 

The VM has two interfaces at 199.63.64.154 and 10.10.64.154 and uses the following ports:

80: Web server
21: File Transfer Protocol (FTP)
22: Secure Shell (SSH)
53: Domain Name Server (DNS)
Workflow
﻿

1. Log in to the VM ubuntu20 using the following credentials: 

Username: trainee
Password: CyberTraining1!
﻿

2. Open a Terminal and escalate privileges to root by running the following and entering the trainee password from step 1:

sudo -s 
﻿

Viewing the existing rules before creating new ones allows analysts to better understand the current state of the firewall. The commands -S and -L each display the existing rules in different formats. Analysts may prefer one or the other option, depending on the type of information they are seeking.

﻿

3. Display the rules per direction (input, forward, output) by entering the following command:

iptables -S
﻿

4. Display the rules as a table by entering the following command:

iptables -L
﻿

5. Clear all existing rules in the table by running the following command:

iptables -F
﻿

After clearing the rules, the list of rules shows the three default rules that allow all traffic. Figure 33.1-1, below, displays this output from the command -S
<img width="343" height="79" alt="image" src="https://github.com/user-attachments/assets/49de7ed6-bfd4-4246-bcaf-ac4bec1bb641" />

6. Allow a single host, such as an admin machine, to connect to this server over SSH by running the following two commands:
iptables -A INPUT -p tcp --dport 22 -s 199.63.64.51 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

iptables -A OUTPUT -p tcp --sport 22 -d 199.63.64.51 -m conntrack --ctstate ESTABLISHED -j ACCEPT



7. Block all incoming Internet Control Message Protocol (ICMP) by running the following command:
iptables -A INPUT -p icmp -j DROP



8. Block all connections to this host from incoming FTP access by running the following command:
iptables -A INPUT -p tcp --dport 21 -j REJECT



9. Block all outgoing traffic to an IP address from the ubuntu server by running the following command:
iptables -A OUTPUT -s 10.10.64.154 -j DROP



10. Enter any display command from either step 3 or 4 to output the rules and ensure they match the information presented in Figure 33.1-2, below

<img width="1155" height="209" alt="image" src="https://github.com/user-attachments/assets/b0b2fdbd-957b-4d94-9f19-8af981b262bf" />

Use the information from this lab to answer the next question. The following lab tests these rules to view them in action


-------------

Auditing Tools and Assessment
Testing host firewall rules after creating them allows analysts to ensure the rules work as intended while avoiding conflicts with other software or applications. Analysts may choose from a variety of tools and approaches for testing the configuration of host firewalls. Organizations can also ensure their firewall rules are effective by designing configuration management operating procedures that ensure firewall rules are checked regularly and precisely.

﻿

Auditing Tools
﻿

When assessing firewalls there are multiple types of auditing tools that analysts can use to assist with the process. One type of tool is a packet analyzer, which captures all network traffic over an interface. To use a packet analyzer, a process or application must actively send requests while a packet capture tool, such as tcpdump or Wireshark, captures all packets for the event.

﻿

On a Linux system, tcpdump is a good option for testing firewall rules because it is very powerful and works well with almost any Linux distribution. Tcpdump can capture the raw data as the test is run, then analysts can view the packet capture for later analysis.

﻿

Analysts may use a port scanning tool to generate the traffic and responses for the packet analyzer to capture. Port scanners can craft and send various types of packets to the hosts that are being tested to determine the type of traffic the host firewall allows. Attackers often use port scanners as part of the discovery phase of an attack to detect the ports that are available to use in the attack. 

﻿

Nmap is a popular tool for port scanning. Nmap sends different types of packets to determine the services and ports that are used on the target machine and whether or not the host firewall protects the system. By default, Nmap performs scans for any open Transmission Control Protocol (TCP) ports. Nmap may also be used to send only specific parts of a packet to the firewall to test which ports are being filtered. Nmap can also perform a SYN or ACK scan and send that specific portion of a packet to the target to test the firewall rules.

﻿

Assessment Process
﻿

Analysts can install their preferred packet capture and port scanning tools on an auditing machine to ensure the tools are ready and available for auditing the firewall rule for a system. After setting up the auditing machine, analysts can begin the firewall rules assessment by configuring tcpdump to capture the traffic that is generated during testing. Thereafter, analysts may begin the assessment by scanning for any open TCP ports.

﻿

As outlined in Figure 33.1-3 below, the scan starts by running the SYN scan to check for every available port. This scan can take up to an hour since there are over 65,000 ports. After the scan completes, stop the packet capture and save the results separately from any other packet captures to use as a quick reference for the ports that are open to SYN traffic. While analyzing the results of the packet capture, look for any ports that are open and any traffic that the firewall rules are filtering or restricting.

﻿

After the initial analysis, repeat the process with different traffic, such as User Datagram Protocol (UDP), and continue watching for open ports. Scanning for UDP ports takes much longer than the SYN scan. Scanning every UDP port could take longer than 24 hours. After completing the scan, stop the packet capture and analyze the results. UDP is a connectionless protocol, so UDP scans may produce false positives that incorrectly indicate multiple open UDP ports. Analysts should investigate these ports and may also perform another scan on specific ports to determine which ports are actually open.

<img width="1667" height="588" alt="image" src="https://github.com/user-attachments/assets/58174c06-3940-4c2b-8556-c7bc14a57eb2" />

In addition to scanning for open ports, Nmap can also determine the OS versions that are running. An attacker can use this information to craft custom malware for the target OS and exploit known vulnerabilities in out-of-date and unpatched versions of the OS.


Firewall Rule Reviews


As networks grow, they become more complex. Complex networks are more likely to develop security voids if their organizations do not conduct proper security reviews. This includes reviewing firewall rules for both host and network firewalls. Security teams can create a firewall rule review checklist to ensure that reviews are completed thoroughly and effectively, regardless of the administrator that reviews the rules.


The questions on a firewall rules checklist should consist of reminders that prompt analysts to think about the traffic and what the rules are doing. Firewall rules should be reviewed every few months, multiple times a year to ensure they are properly protecting the hosts and network. Figure 33.1-4 below provides an example of steps that should be included in a firewall rule review checklist. This is also available as an attachment on this task


<img width="1667" height="1389" alt="image" src="https://github.com/user-attachments/assets/818cd02e-d89b-46e5-8ba5-7f5c0f5415b2" />

These are just a few of the examples that organizations can use when creating standard operating procedures regarding host firewalls

--------------


Assess Host Firewall Rules on Linux
The first lab in this lesson added the following four rules:

Enable SSH access for 199.63.64.51 to 199.63.64.154 (ubuntu20)

Disable all ICMP traffic to ubuntu20

Disable FTP access for 199.63.64.51 to 199.63.64.154 (ubuntu20)

Disable all outbound access from 10.10.64.154 (ubuntu20) to anywhere

In the next lab, test these rules and verify whether they are successfully blocking and enabling access, per each of their goals. 

﻿

Workflow
﻿

1. Log in to the VM kali-hunt using the following credentials: 

Username: trainee
Password: CyberTraining1!
﻿

2. Open a Terminal and change to the root user with the following command:

sudo -s
﻿

3. Scan the host Ubuntu to verify which ports are open on 199.63.64.154 by entering the following Nmap command:

nmap -sV 199.63.64.154
﻿

Figure 33.1-5, below, displays the output from this step. SSH is open, which is expected since rule 1 was created to allow access from this host


<img width="1012" height="317" alt="image" src="https://github.com/user-attachments/assets/29845a7e-e5de-4523-8cb6-87e34b1ef0b1" />

5. Attempt to connect to ubuntu20 over SSH with netcat:
nc 199.63.64.154 22



A successful connection displays the banner SSH-2.0-OpenSSH_8.2p1 Ubuntu-4ubuntu0.4, as displayed below in Figure 33.1-6. This banner indicates that the firewall did not block this connection, due to rule #1


<img width="614" height="118" alt="image" src="https://github.com/user-attachments/assets/531a5104-9155-4385-9463-9f9998852946" />


NOTE: After this netcat command completes and returns the output above, close the Terminal window or select the CTRL+Z shortcut on the keyboard to stop the netcat process.


6. Check firewall rule #2 by attempting to ping 199.63.64.154 with the following command:
ping 199.63.64.154



This command does not output any successful replies, which indicates that ICMP is blocked, as intended.


7. Check whether FTP access is blocked to the server ubuntu20, per rule #3, by attempting to access the server with the following command:
nc 199.63.64.154 21



This command does not display any information, as presented in Figure 33.1-7, below. This indicates that the port is closed or inaccessible from this IP address due to firewall rule #3

<img width="573" height="50" alt="image" src="https://github.com/user-attachments/assets/2919eac9-4f6f-4b7d-bca8-153753c73196" />



8. View the ports that are being used by the private IP interface on ubuntu20 at 10.10.64.154 with the following Nmap command:
nmap -sV 10.10.64.154



This command does not return any ports due to rule #4. Besides scanning, another avenue for checking this rule is to attempt a connection over SSH.


9. Attempt to connect to ubuntu20 on the interface with the private IP 10.10.64.154 over SSH with the following command:
nc 10.10.64.154 22



The connection also does not succeed because outbound traffic is not allowed from the interface at 10.10.64.154 on ubuntu20.


Use the information from this lab to answer the following question.

-------------

Identifying Malicious Activity in Firewall Logs
When an analyst suspects that malicious activity is occurring in a system, host firewall logs are one of the first places they should look for more information. Firewalls are often one of the first defenses in host security. Regularly monitoring and analyzing firewall logs should be a standard part of an organization's process for improving overall security. This standard may help analysts uncover indications of unusual traffic and patterns that suggest malicious activity, even before any serious damage takes place.

﻿

To effectively analyze firewall logs, analysts must first build a complete understanding of the full network topology. However, the network topology for organizations changes regularly so analysts must also review it regularly to stay as up-to-date as possible. Basic information to watch for in these regular reviews include systems and servers that are communicating with the host being analyzed and IP addresses and ports the host is regularly using. 

﻿

After establishing a baseline view of the network topology, analysts can more effectively identify suspicious traffic and activity. The following information, in particular, may provide indications of unusual activity:

Outbound traffic
Port scans
Geolocation
Denied traffic
Outbound Traffic
﻿

A common misunderstanding about firewalls is that they are only designed to stop malicious incoming traffic. In fact, firewalls can also keep malicious requests from within an organization from traveling out of the network, as well. Outbound malicious traffic may occur when a user installs malicious software, or if a system is already compromised and an attacker is trying to communicate with their malicious infrastructure. This type of traffic may also indicate that an attacker is attempting to exfiltrate data. Outbound traffic information to monitor include the following:

Size of files being transferred in and out
Allowed traffic on the access control list
Completed account changes
Number of resources in use
﻿

Port Scans
﻿

Port scans often indicate that an attacker is targeting a system and looking for open ports. Firewall logs Firewall logs may indicate a port scan if they display a series of multiple requests to a single IP address using a wide range of ports. If an analyst discovers this type of behavior, they should block the originating IP address. 

﻿

Geolocation
﻿

Traffic geolocation can also be insightful for analysts to monitor. For example, an analyst may notice that a Windows machine is attempting to connect to an IP address located in Russia through a port that is infrequently used. This is a likely sign that either an attacker is targeting the system or that the system has already been compromised. Analysts should block any inbound and outbound traffic from a geolocated IP address of any known attackers as well.

﻿

Denied Traffic
﻿

Another important piece of information that analysts should look at when monitoring firewall traffic is any inbound or outbound traffic that has been denied. Denied inbound traffic suggests that the host firewall found something that was either suspicious or did not pass through any of the firewall rules. The IP addresses or ports that are found in the denied logs may act as early warnings to security teams. This sort of behavior may indicate that attackers are targeting an organization and attempting to use the denied IP addresses or ports as part of an attack.

﻿

Denied outbound traffic may also be very concerning. The first assumption that analysts should explore is a possible misconfiguration in the host firewall rules that are setup. One or more rules may be mistakenly blocking IP addresses or ports that certain applications or software may be using. After ruling out possible misconfigurations, analysts should determine which firewall rules denied the traffic and why. These are possible indicators of malicious activity. Any IP addresses or geolocations that were discovered as part of the denied traffic can be used to hunt for activity on a system or network

--------


Analyze Host Firewall Logs
A newly-hired Linux system administrator configured a new server with the following iptables firewall rules:

Enabled wide open SSH access
Disabled all ICMP traffic
Disabled FTP access
Drop everything else
Explore the iptables logs to discover whether any malicious activity occurred with these firewall rules. Figure 33.1-8, below, presents the iptables rules that were specifically defined:

<img width="1122" height="616" alt="image" src="https://github.com/user-attachments/assets/faef8cd6-7e7c-41ac-9c9f-c0447f1d146e" />

Workflow


1. Log in to the VM kali-hunt using the following credentials: 
Username: trainee
Password: CyberTraining1!



2. Open Firefox and select the bookmark Discover - Elastic.


3. Log in to Elastic with the following credentials:
Username: trainee@jdmss.lan
Password: CyberTraining1!



4. Set the date range for the activity from August 28th, 2022 @ 20:00:00.000 to August 28th, 2022 @ 20:30:00.000, as displayed in Figure 33.1-9, below:

<img width="481" height="53" alt="image" src="https://github.com/user-attachments/assets/0e566a03-38f6-4a0c-aa31-33b0a9162dea" />


5. Filter the results from the previous step by enabling the following columns, as displayed in Figure 33.1-10, below:
log.file.path
Message

<img width="375" height="257" alt="image" src="https://github.com/user-attachments/assets/f12f838c-6983-4ec9-925e-a05f69afb4f4" />

6. Examine SSH activity in the logs by setting the query as follows:
agent.name:"uws" and log.file.path:"/var/log/kern.log" and "iptables" and "SPT=22"



This produces 27 results that each occur within one or two seconds from the host 199.63.64.51. This indicates an SSH bruteforce attempt.


7. Filter the SSH authentication and iptables logs to focus on a single host by running the following query:
agent.name:"uws" and log.file.path:"/var/log/auth.log" and "199.63.64.51"



This displays numerous failed login attempts, followed by three successful attempts. Use the information from this task to answer the following question

drop does not send icmp back while reject does


--------

### CDAH-M33L2-Elastic Stack as a SIEM ###


Elastic Stack Overview
A SIEM aggregates data from multiple data sources. The data sources vary from environment to environment but typically include applications; infrastructure systems, such as servers and databases; security controls, such as firewalls; or networking equipment, like switches and routers.

﻿

The Elastic Stack comprises Elasticsearch, Logstash, Kibana, and Beats, to create a complete open-source log management system. The Elastic Stack assists analysts by taking care of the collection, parsing, storage, and analysis of any log data ingested into the platform. 

﻿

How Elastic Stack Works
﻿

Elastic Stack uses three components to parse and store ingested data: documents, indexes, and inverted indexes. These three components work together to quickly convert, index, and create mappings to the uploaded data for quick results from a query.

﻿

Documents
﻿

When data is uploaded to Logstash, the data is stored as a document. In the context of Elastic Stack, a document is the contents of the uploaded data, such as Sysmon data from a Windows client. Once the data is transformed into a document, the data is converted to JavaScript Object Notation (JSON) format and is assigned a unique Identifier (ID) so that the data can be located later during a query.

﻿

Indexes
﻿

Indexes are a way to sort data into their own categories. An index is a collection of documents that are similar. For example, a Linux syslog may be uploaded through Beats with an index name of onion:so-beats-date(2022.08.31), and a Windows Sysmon log with the same name may also be uploaded through Beats. Dozens of other common indexes exist, such as the following:

so-o365 for Microsoft 365 logs.
so-okta for Okta authentication logs.
so-cisco for Cisco® logs.
so-snort for Snort® Intrusion Detection System (IDS) log data.

When querying for data, the index for the query needs to be known. Otherwise, the content being searched for may not be found. For example, if the username trainee is searched for under the index so-o365, Elastic searches through only the so-o365 index; it does not search through the other indexes. Searching all indexes at once with the _index:* option is possible, but such a search is processing intensive and is slower to perform. Analysts should specify one or multiple indexes, rather than all of them, to avoid slowing down the system.  

﻿

Inverted Indexes
﻿

The speed of Elastic Stack is most obvious using an inverted index, illustrated in Figure 33.2-1. The inverted index creates a data structure that essentially links a term (content of a file) that is in a document or set of documents. The index then creates an internal mapping that allows for quick access and returns the documents that contain those terms when a query is performed



<img width="1667" height="1123" alt="image" src="https://github.com/user-attachments/assets/67fb24de-1c0d-40d7-92d3-77def1077206" />

Elastic Stack Tools


As stated earlier, Elastic Stack contains four tools: Elasticsearch, Kibana, Logstash, and Beats. Each tool, as shown in Figure 33.2-2, plays an important role in log searching, analyzing, and visualizing

<img width="1667" height="588" alt="image" src="https://github.com/user-attachments/assets/611b1cdd-a0b1-4f65-9b13-757ac79ce4cf" />

Elasticsearch


Elasticsearch is a distributed search engine tool that can be used for such actions as searching for a specific Internet Protocol (IP) address or analyzing odd traffic patterns. With Elasticsearch, analysts can store, search, and analyze data quickly and efficiently, in real time. Searches with Elasticsearch are rapid because the tool uses indexes, discussed earlier, rather than directly searching the text. 


Logstash and Beats


Logstash is a log aggregator that collects and processes data from multiple sources and then converts and ships it to Elasticsearch. Logstash can ingest data from multiple sources simultaneously and then send it on for collection. Beats are lightweight log forwarders that can be used as agents on hosts to track and forward specific types of data. Logstash and Beats may be combined to aggregate Beats data, process it, and forward it in near-real time to the next component in the pipeline, such as Elasticsearch.


Kibana


Kibana is the data visualization and management tool that Elasticsearch uses to provide customized real-time graphs, charts, and maps. Kibana allows users to visualize the Elasticsearch data that has been collected and navigate the Elastic Stack features. Analysts can select how they want to shape their data and set up an interactive visualization to view the data from a different viewpoint. Kibana can also be used for log analysis to search through and visualize data that was collected.


Supported Log Formats


Elastic Stack supports many log formats, depending on the environment and Operating Systems (OS) that an organization is using. Analysts can use the syslog plug-in to read syslog messages as events over the network. This may also be used for systems or network devices that do not have their own log collectors as a way to receive logs from those devices.


For network logs, Elastic Stack can be configured to interface with Zeek or Suricata. For networks that use Zeek as a traffic analyzer, Elastic Stack’s Elastic Agent can collect logs from Zeek. This allows analysts to view the data collected by Zeek in the Elastic Stack and use the Elastic Stack tools and capabilities to analyze the data. This can also be done with organizations that use such tools as Suricata or that have syslogs set up for system logs for any network devices


----------

Features of a SIEM
A SIEM collects data from network hosts, including switches, routers, servers, Domain Controllers (DC), and workstations. A SIEM stores, normalizes, aggregates, and applies analytics to data, which allows analysts to discover trends, detect threats, and enable organizations to investigate alerts. Most SIEMs offer similar features and capabilities but use different tools to accomplish their objectives. Some typical features that a SIEM offers are log collection, log processing, querying, and detection rules and alerting.

﻿

Log Collection
﻿

In a large environment, several million logs may be generated at any given time across multiple devices on a network. These logs may be in many different formats, such as host-based security logs, network traffic logs, or logs that come from host devices. Getting all these logs to the central indexer is the first step in the SIEM log collection process.

﻿

The Elastic Stack uses a combination of Beats and Logstash, consisting of multiple data pipelines, to aggregate all the data collected. Because a huge amount of data may exist, it is recommended that multiple Logstash instances are created to provide an efficient way for the data to flow and to provide redundancy if one of the instances fails. 

﻿

Log Processing
﻿

Once all the data is collected and indexed into a central server, processing and parsing the data are among the most crucial tasks that a SIEM performs. Any information collected from the different data sources generates logs in different formats. Data normalization is an important step to be able to search and analyze the data. Data normalization is the process of breaking down all the log messages and formats into meaningful field names, mapping the field types correctly in a search-based tool such as Elasticsearch.

﻿

The Elastic Stack uses Logstash for the data normalization process. Data that is not correctly parsed is meaningless for those attempting to analyze it in Kibana. Logstash also supports multiple plug-ins to assist with different log formats; with adding specific fields, such as geographic information, to the data; and with adding and dropping fields within the data. The Logstash pipeline is the most important piece of the Elastic Stack, and its performance should be monitored accordingly. 

﻿

Querying
﻿

Once the data is collected and parsed, it may be queried. Queries allow analysts to conduct an investigation into any logged events. This allows analysts to pinpoint security vulnerabilities that may exist within an organization or to perform a hunt for any indications of an attack. 

﻿

In the Elastic Stack, querying is done with Kibana. Because all the data is normalized during the log processing step, users can search for a field using the Kibana Lucene syntax, and Elastic searches for it across all data sources available.

﻿

Detection Rules and Alerting
﻿

Detection rules can detect behaviors or suspicious events that an analyst configures, and alerts can inform analysts that these behaviors or events are occurring. This saves analysts time in having to manually parse through logs for specific behaviors or events.

﻿

The Elastic Stack has prebuilt detection rules as well as the ability for organizations to create their own detection rules. The Elastic Detection Rules GitHub repository contains static rules as well as code used for testing and integration with the Kibana Detection Engine. Analysts can add rules from the repository as Python modules and then use the commands given to test or create new detection rules. All the detection rules can be managed and configured from the Elastic Security Detection Engine web server.

﻿

To avoid false positives from the detection rules, analysts should fine-tune detection rules before configuring them to alert analysts of any malicious behavior.

﻿

The Elastic Stack does not come with prebuilt alerting tools, but plug-ins can be installed to alert analysts to suspicious patterns or behaviors occurring within the network traffic. If the system logs an unusual amount of failed logins for a single user, an alert can be sent out to an analyst to investigate this and stop an attack from occurring


---------

Creating Elastic Dashboards
One of the most popular features of the Elastic Stack is Kibana’s ability to build dashboards of data in the forms of charts, maps, and graphs. Dashboards can be created for any environment to show critical data types. Kibana can provide data from multiple points of view, thus offering complete visibility into the activity of a network. 

﻿

Creating dashboards in Kibana can be complex, and users must know in advance the fields they wish to display. Kibana offers multiple prebuilt dashboards, such as a Windows Sysmon dashboard that displays IP addresses, source and destination ports, and hostnames. Kibana also offers custom dashboards. For example, a dashboard might visualize all the Domain Name System (DNS) traffic within a network and display DNS query count, average response times, or DNS request status. Another possibility is a dashboard of data comprising potential indicators of malicious activity. Dashboards in Kibana may use the following data types:


Suspicious command lines
High number of failed logins
Known malicious hashes
Any remote access activity
Any unauthorized software
Create an Elastic Dashboard
﻿

The following lab includes two workflows: one to create a prebuilt Elastic Stack dashboard and one to create a customized Elastic Stack dashboard.

﻿

Create a Prebuilt Dashboard
﻿

Complete the steps in the following workflow to create a prebuilt dashboard using Elastic Stack.

﻿

Workflow
﻿

1. Open the Virtual Machine (VM) kali-hunt. The login credentials are as follows: 

Username: trainee
Password: CyberTraining1!
﻿

2. Open a web browser, and log in to Elastic, using the following credentials:

Username: trainee@jdmss.lan
Password: CyberTraining1!
﻿

3. Select the hamburger menu icon in the upper left corner of the Elastic User Interface (UI), and select Dashboard:

﻿
<img width="339" height="544" alt="image" src="https://github.com/user-attachments/assets/55d8fa88-c12c-4589-89c6-aa6b31cef2dd" />



4. On the Dashboards page, enter Sysmon in the search field, and locate and select Security Onion - Sysmon.


5. On the Sysmon dashboard, set the time range to Aug 26, 2022 @ 00:00:00.000 to Sep 1, 2022 @ 23:59:59.999.


Each pane contains an overview of specifically filtered information, which the analyst may then take back to the Discover page to gain more context.


Create a Custom Dashboard


The dashboard provided thus far is prebuilt. Complete the steps in the following workflow to create a custom dashboard that displays failed Secure Shell (SSH) logins for a Linux host and command-line activity for a Windows host.


Workflow


1. Return to the hamburger menu, select Dashboard, and select Create Dashboard.


2. Select Create Visualization.


3. In the query field, enter the following query, and select Update:
agent.name:"uws" and "Failed password" and "sshd"




4. Expand Available Fields in the left pane, and select and drag message.keyword to the center pane:


<img width="1049" height="534" alt="image" src="https://github.com/user-attachments/assets/7d41f5e0-08f0-4d75-935b-e5a478723181" />

5. Change the Bar vertical stacked option to Table to see the query results, shown in Figure 33.2-5

<img width="916" height="361" alt="image" src="https://github.com/user-attachments/assets/a7b37ff9-60ee-4b2a-9cd1-a6d764b4bb99" />
6. Select Save and Return to return to the Dashboards page.


7. Again, select Create Visualization. This time enter the following in the query field:
process.command_line:*




8. Select and drag process.command_line to the center pane, and change the Bar vertical stacked option to Donut.


9. In the Slice by pane on the right side of the interface, select the link Top values of process.command_line. Set the number of values to 1000, expand the Advanced option, and turn off the option Group other values as “Other”

<img width="386" height="343" alt="image" src="https://github.com/user-attachments/assets/4c7f10de-b58f-4b3e-8e95-1537a71b8912" />

10. Select Save and Return to return to the dashboard.


11. Drag the donut next to the previously created table.


12. Hover the mouse over the colored portions of the donut to display the corresponding command line and the count of how often it has been seen.


Figure 33.2-7 shows the custom dashboard providing information from two sources, illustrated with a table and a donut

<img width="1595" height="472" alt="image" src="https://github.com/user-attachments/assets/11c7bd0b-4d0f-4763-b7a7-1c747e018f90" />

13. Select Save, and name the dashboard IR Dashboard. Enable Store time with dashboard to keep the time range linked to this dashboard, and select Save.


14. Select Share > Permalink > Copy Link, and save the link as a bookmark. (This is the quickest way to return to the dashboard; it avoids the need to browse to the Dashboards page, search for the dashboard name, and load the page.)


Numerous items may be added to the dashboard, such as hashes of value, Remote Desktop Protocol (RDP) connections, and remote connections.


------------------

### CDAH-M33L3-Email Threats ###

Overview of Email Protocols
Email is an essential form of communication for organizations, however, it can also pose one of the greatest risks. If employees are not properly trained, they may misuse email tools and fall for common email attacks. 

﻿

Email Protocols and Ports
﻿

The protocols email tools use to function act as a set of rules that instruct the email client how to transmit the data to or from a mail server. Protocols allow users to send and receive messages over the network correctly and in accordance with how an organization wishes to share email between mail servers. Email protocols establish communication between a sender and receiver for the transmission of email. The following are three basic types of email protocols that are used for sending and receiving emails:

Simple Mail Transfer Protocol (SMTP)

Post Office Protocol Version 3 (POP3)

Internet Messaging Access Protocol (IMAP)

Each protocol has a different way to handle incoming and outgoing email traffic. SMTP is the protocol that handles message transfer from server to server or mail client to server. Since this protocol handles sending emails it is considered the outgoing Message Transfer Agent (MTA). POP3 and IMAP are both Message Access Agent (MAA) because they each handle incoming email traffic and they both have different ways to retrieve or access any email traffic. SMTP allows users to send email messages, while IMAP and POP3 allow users to receive emails.

﻿

Each email protocol has specific ports that are used for plaintext or encrypted communications. These ports define how the message is sent and whether or not the communication is encrypted. The next section illustrates how each protocol works and with which ports.

﻿

SMTP
﻿

SMTP is a set of interaction guidelines that allow software to transmit email over the internet. As an MTA, SMTP is an outgoing protocol that sends emails to the recipient. Its main goal is to establish communication between a sender's email client and multiple email servers. As illustrated below in Figure 33.3-1, the sender's client machine contacts their local SMTP server, which then contacts the destination host's SMTP server to deliver the email. The mail client and mail servers may be set up to recognize already established servers. This setup allows the servers to communicate with each over a connection established through email port 25. SMTP mail servers may also be set up to handle error messages such as a wrong email address.
<img width="1668" height="597" alt="image" src="https://github.com/user-attachments/assets/4e897d4b-4d1c-4dc6-a07f-9ea477f16660" />

There are four ports available for SMTP. Each port offers a different type of encryption for email traffic:
25: Used to send messages in plain text.
2525: An alternative to port 25 that can be encrypted over Transport Layer Security (TLS), but is not the standard port and is rarely used.
587: A secure port that requires an explicit TLS connection. If the email server does not support TLS, the message will be sent in plain text. 
465: A secure port that works implicitly over Secure Sockets Layer (SSL) or TLS connections. If the email server does not support SSL connections, the operation will be aborted. This is a deprecated port but can be seen in use on older applications that cannot support another port.

POP3


As an MAA, POP3 accesses messages from a recipient's mail server. POP3 clients connect to the mail server, retrieve all messages, save the messages on the client computer when connected to the internet, then delete the messages from the mail server. This process is illustrated below in Figure 33.3-2.

<img width="1668" height="597" alt="image" src="https://github.com/user-attachments/assets/f4b9e51f-c724-4127-adfe-9f59d99b4953" />

The POP3 protocol is useful when users have intermittent internet connections, such as dial-up access, or are in situations where the email server has limited storage space. This allows users to read and edit the obtained messages when offline. Deleting downloaded messages also reduces the amount of space that an email account uses on the email or web server. Modern POP3 email clients allow users to keep a copy of the messages on the email server. However, this is not the default functionality, so users must explicitly set up this option.


The following two ports are available for POP3:
110: The default port for POP3. This port is not encrypted. 
995: The encrypted port for POP3. This port works over TLS and SSL.

IMAP


IMAP is suitable for users who may need access to their email on multiple different devices such as a cell phone or multiple different computers. When a user reads an email message using IMAP, they are reading it from the email server, as Figure 33.3-3 illustrates, below. The message is not downloaded or stored on a computer the way it is with POP3. As a result, users can access their emails from different devices anywhere in the world such as a cell phone, a computer, or a public device

<img width="1668" height="597" alt="image" src="https://github.com/user-attachments/assets/9ea83afc-136e-4370-a035-aa09b6997137" />

The IMAP protocol is also useful when there are multiple users who need access to a shared mailbox since IMAP supports the connection of multiple users to a single email server. IMAP allows users to efficiently create and edit folders, and permanently delete or search through messages. Users can also set email flags and sort through emails based on specific attributes about those email messages. All messages remain on the email server until users delete them. 


The following two ports are available for IMAP:
143: The default port for IMAP. This port does not provide any encryption. 
993: The secure port for IMAP. This port works over TLS and SSL encryption.

---------------

Email Threats
Malicious cyber actors can uncover precious information and access a direct line of communication with senior leadership by accessing an organization's emails. These actors have discovered multiple ways to wield emails as tools to target users and attack organizations. The MITRE Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK®) framework has identified the following six methods that attackers commonly implement when attacking through email:

Spearphishing Attachment (T1566.001)

Credential Theft Through Phishing (T1566.002)

Business Email Compromise (T1586.002)

Service Exhaustion Flood (T1499.002)

Authentication Attacks on Email Servers (T1110.004)

Vulnerabilities in Email Servers (T1190)

Phishing: Spearphishing Attachment (T1566.001)
﻿

Spearphishing attachments are attachments delivered through email tailored for a specific victim. These types of attachments have a higher likelihood of success that the victim will open the attachment. Attackers intentionally embed malware in the attachments in an attempt to compromise the victim machine and to create a foothold into the target environment.

﻿

Credential Theft Through Phishing (T1566.002)
﻿

Credential theft through phishing occurs when attackers trick users into giving away their personal information or passwords in an email or through a fake website meant to look like the real website. These emails often use verbiage to make them seem urgent, requiring the victim to act as soon as possible. These emails may also attempt to instill fear into the recipient to cause them to take action in a rushed manner. In either case, the goal is to discourage the victim from taking time to think rationally about the email or report the email to any authorities.

﻿

Business Email Compromise (T1586.002)
﻿

The business email compromise is a unique method in which an attacker gains the credentials of a business email account and then uses that account to send emails. Since the email is coming from within an organization's email domain, it likely bypasses most of the email filtering controls. Communications coming from recognized business addresses are also more likely to be trusted by the recipient as they appear exactly the same as any normal business email. It's easy to confuse compromised business emails as colleagues looking for help or needing information.

﻿

Service Exhaustion Flood (T1499.002)
﻿

Service Exhaustion Flood attacks are used to impede an organization's email infrastructure. Rather than providing attackers access to email accounts, email servers, or end user machines, these types of attacks send thousands of requests a minute to their targets. The flood of requests makes it impossible for the target to identify and access legitimate messages. These types of attacks can also be used to overload the email server so that legitimate emails cannot be sent nor received.

﻿

Authentication Attacks on Email Servers (T1110.004)
﻿

Authentication attacks on email servers occur when attackers gain access to the email server instead of individual email accounts. Malicious actors may accomplish this through brute force attacks or credential stuffing. Malicious actors may also gain access to an administrator's email account very easily, if the account uses that same password to administer the email server. If a malicious cyber actor is able to gain access to an email server, they can then read the emails of all users in an organization. This is more efficient and powerful than compromising just one account, as is the case in a business email compromise attack.

﻿

Vulnerabilities in Email Servers (T1190)
﻿

Malicious cyber actors also exploit email servers through any vulnerabilities they may have. Attackers may be able to gain remote code execution on the email server this way. This provides the attacker access to all email content, as well as access to the local network on which the email server resides. An attacker can then infect other servers and hosts within the internal network to cause more damage


----------

Discover Threats Through Email
An accountant named Gabriel received two emails in his Google account. As displayed in Figure 33.3-4, below, both emails seem to indicate suspicious activity on the account.


<img width="1207" height="221" alt="image" src="https://github.com/user-attachments/assets/9958daa0-62d6-4277-b5d8-eb59f2c80367" />


Discover Email Threats


Review the emails in Gabriel's inbox to determine the type of email threats that may be present.


Workflow


1. Log in to the Virtual Machine (VM) win-hunt using the following credentials: 
Username: trainee
Password: CyberTraining1!



2. From the desktop, open Outlook to view Gabriel's unread emails.


The inbox displays two unread emails.


3. Select the first email with the subject Unusual Sign-in Activity Detected.


The sender is no-reply@gmail.com, which initially seems legitimate. 


4. Select the link in the email.


The link opens a realistic login page for Google in a Microsoft Edge browser. The Uniform Resource Locator (URL) seems legitimate, however attackers are known to use similar domain names as the sites they are copying so that links seem legitimate and the email seem more authentic. The login page also successfully mimics the real Google login page. Attackers use these tricks to convince users they are on the real website so that when the users attempt to login, they unknowingly send their credentials to the attacker's fake infrastructure.


5. Exit the Edge browser and return to Outlook. 


6. Right-click on the email that was just opened and select Message Options.


7. In the window Message Options, identify where the email originated from by reviewing the information in the section Internet headers.


In this lab environment, the "Received:" line lists that the email came from 127.0.0.1. If the email legitimately arrived from Google, this section would list one of Google's mail server Internet Protocol (IP) addresses in this section. 


8. Exit the window Message Options by selecting Close and returning to Outlook.


9. In the inbox, select the second email with the subject Account Details.


The second email was sent from the same email address as the first email and it includes an attachment. 


10. Open the attachment by double-clicking on the file report.zip and selecting open when prompted to open or save the file to the computer.


Selecting open displays a file explorer window with the file report.csv. 


11. Open the file by double-clicking report.csv and selecting Run in the dialog box Open File - Security Warning. 


Opening the file displays a pop-up window with the message Google Security Report for gabriel@gmail.com. 


12. In the Google Security Report pop-up window, select OK.


This allows Excel to open the file and display a report. The report secreport is not malicious, but may contain malicious macros. Although the file report.csv was benign, it wasn't a Comma-Separated Values (CSV) file. In fact, it was an executable whose file extension was hidden in Windows. The executable report.csv.exe ran code on the system. An attac ker could have us ed this functionality as an entry point into the system


----------

Email Protections
Although many attacks through email cannot be stopped, there are protections that organizations can use to mitigate many of these types of attacks. To keep organizations safe, both the email client and email server must be secure. It is also essential to train employees and inform them about spam and phishing attacks and the threat that they pose to an organization. And, even with well-trained employees, organizations must also secure the email server against attacks that may get through. 

﻿

Email Protection Options
﻿

The following are some steps that organizations can take to protect themselves from email threats:

Implement a Secure Email Gateway
Secure Data Archives
Implement Antivirus Software and Firewalls
Use a Sandbox for Scanning Emails
Implement a Secure Email Gateway
﻿

A Secure Email Gateway (SEG) is a device or software that helps analysts monitor and filter incoming and outgoing emails. SEGs allow analysts to flag suspicious and potentially malicious emails and alert users to either leave the emails unopened or stop the emails from being delivered altogether.

﻿

Analysts can also set up inbound and outbound rules with an SEG to redirect suspicious traffic and manage blocked emails. Analysts can then scan the emails for malicious content. If an analyst deems re-routed or blocked emails legitimate, they can allow them to proceed to the intended recipient.

﻿

Secure Data Archives
﻿

Many businesses have automated email archiving solutions set up to keep backups of emails for business or legal purposes. The email archive system must be as secure as the main email server. If an attacker were to compromise the archive system, they could have access to very sensitive data. 

﻿

Secure data archiving starts with organizations implementing an email retention policy that covers the process for archiving emails and the security measures that must be set up. The email retention policy can provide users with quick and safe access to archived data and ensure the security of data that is archived. 

﻿

Implement Antivirus Software and Firewalls
﻿

While many organizations use antivirus software to protect against malware and other attacks, most antivirus solutions can also be used as protection for emails. If a user does open a malicious attachment in an email, antivirus solutions can be used to stop the malicious payload from executing and alert analysts of potential malware on the system. Some antivirus software can also be used to filter out spam and alert users of emails that may contain spam.

﻿

Many modern firewalls also offer services to stop spam, viruses, and other malicious content before they reach the users. Organizations can set up spam and virus filters on their firewalls that detect new threats, and block any emails that contain malware. They can also be set up to alert analysts whenever an email is blocked so the analysts can triage the incident, as needed. Analysts can also use this opportunity to ensure legitimate mail traffic is not accidentally blocked. Regularly monitoring traffic that passes through the spam and virus filters helps analysts ensure these tools are working as intended.

﻿

Use a Sandbox for Scanning Emails
﻿

Malicious emails may contain attachments that deliver malicious payloads. Organizations can use sandboxing as a defensive measure against these types of email attacks. To conduct sandboxing, administrators and analysts isolate and analyze potentially malicious emails in a secure environment. The benefit to sandboxing is that analysts do not have to risk compromising the network while they analyze the email.

﻿

For more sophisticated attacks, sandboxing allows analysts to view more detailed information about email threats and can give them extra time to detect and stop an attack from happening. 

﻿

Proper Email Hygiene
﻿

Even with implementing the above steps to protect organizations from email threats, the best step a business can take to protect their network is to properly train all of their employees on proper email hygiene. Everyday attackers create new schemes to trick users into divulging information or opening malicious attachments. It is important to keep all of the employees up-to-date on the new strategies that attackers are using to trick users and make them aware of what to look for in suspicious emails and attachments.

﻿

One of the best ways to train employees is to use simulated phishing emails to prevent employees from becoming complacent. This also allows security teams to identify employees that may need additional support if they are more prone to phishing attacks. Employees should be aware of the latest social engineering tricks that attackers use and avoid opening any emails or email attachments from unfamiliar senders.


--------------




































































































